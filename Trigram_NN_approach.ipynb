{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_dnH15Hy8DQ"
      },
      "outputs": [],
      "source": [
        "#In this code segments we will dive into creating Trigram model using countin. Have a dataset names, this contains list of names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "i3a7AVLNzUCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt','r').read().splitlines()"
      ],
      "metadata": {
        "id": "KRQjTdi0zpUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = sorted(list(set(''.join(words))))\n",
        "stoi = {value:key+1 for key,value in enumerate(all_characters)}\n",
        "stoi['.'] = 0\n",
        "itos = {value:key for key,value in stoi.items()}"
      ],
      "metadata": {
        "id": "yQw158Hs1M8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs=[]\n",
        "ys=[]\n",
        "num=0\n",
        "for word in words:\n",
        "  word = '.'+word+'.'\n",
        "  for ch1,ch2,ch3 in zip(word,word[1:],word[2:]):\n",
        "    ix1,ix2,ix3=stoi[ch1],stoi[ch2],stoi[ch3]\n",
        "    xs.append([ix1,ix2])\n",
        "    ys.append(ix3)\n",
        "    num+=1\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "wHfXyAj2zXT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xs,num_classes=27).float()"
      ],
      "metadata": {
        "id": "Id2JFDU1RqUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = xenc.view(-1,2*27)"
      ],
      "metadata": {
        "id": "pzmAKtLKSPsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "ginit = g.get_state()"
      ],
      "metadata": {
        "id": "hgd42Kp4WYyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn([54,27], generator=g,requires_grad=True)"
      ],
      "metadata": {
        "id": "oX4JYw2iSgcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=0\n",
        "for i in range(1000):\n",
        "  logits = xenc @ W\n",
        "  counts = torch.exp(logits)\n",
        "  P = counts/counts.sum(1, keepdim=True)\n",
        "  loss = -P[torch.arange(num),ys].log().mean()\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "  W.data += -50*W.grad\n",
        "  if x%100==0:\n",
        "    print(loss)\n",
        "  x+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTr8Rw5zUMZt",
        "outputId": "32360297-5322-4b1e-a28b-6042298f96db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.1863, grad_fn=<NegBackward0>)\n",
            "tensor(2.2634, grad_fn=<NegBackward0>)\n",
            "tensor(2.2484, grad_fn=<NegBackward0>)\n",
            "tensor(2.2437, grad_fn=<NegBackward0>)\n",
            "tensor(2.2415, grad_fn=<NegBackward0>)\n",
            "tensor(2.2403, grad_fn=<NegBackward0>)\n",
            "tensor(2.2395, grad_fn=<NegBackward0>)\n",
            "tensor(2.2390, grad_fn=<NegBackward0>)\n",
            "tensor(2.2386, grad_fn=<NegBackward0>)\n",
            "tensor(2.2384, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.set_state(ginit)\n",
        "for i in range(10):\n",
        "  ix1=0\n",
        "  ix2=0\n",
        "  out=[]\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1,ix2]), num_classes=27).view(-1,54).float()\n",
        "    logits = xenc @ W\n",
        "    counts = torch.exp(logits)\n",
        "    P = counts/counts.sum(1, keepdim=True)\n",
        "    ix1=ix2\n",
        "    ix2 = torch.multinomial(P,num_samples=1,replacement=True,generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2==0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsISBzkyWxDD",
        "outputId": "6418a172-ae17-441b-973b-60b0e733413d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aunide.\n",
            "aliagar.\n",
            "ushiay.\n",
            "adin.\n",
            "adi.\n",
            "ritoleras.\n",
            "get.\n",
            "adannaa.\n",
            "zabileniassibdainrwi.\n",
            "ol.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNWTSMd5XGKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}